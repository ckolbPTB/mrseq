{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# T1 Mapping - Radial Look Locker Sequence\n",
    "\n",
    "T1 mapping using a continuous golden radial Look Locker inversion recovery sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MRzeroCore as mr0\n",
    "import numpy as np\n",
    "import torch\n",
    "from cmap import Colormap\n",
    "from einops import rearrange\n",
    "from mrpro.algorithms.reconstruction import DirectReconstruction\n",
    "from mrpro.data import CsmData\n",
    "from mrpro.data import KData\n",
    "from mrpro.data import SpatialDimension\n",
    "from mrpro.data.traj_calculators import KTrajectoryIsmrmrd\n",
    "from mrpro.operators import DictionaryMatchOp\n",
    "from mrpro.operators.models import TransientSteadyStateWithPreparation\n",
    "from mrpro.phantoms.coils import birdcage_2d\n",
    "\n",
    "from mrseq.scripts.t1_radial_look_locker import main as create_seq\n",
    "from mrseq.utils import combine_ismrmrd_files\n",
    "from mrseq.utils import sys_defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Settings\n",
    "We are going to use a numerical phantom with a matrix size of 120 x 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matrix_size = [120, 120]\n",
    "rf_flip_angle = 9\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "fname_mrd = Path(tmp.name) / 't1_radial_look_locker.mrd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Create the digital phantom\n",
    "\n",
    "We use the standard Brainweb phantom from [MRzero](https://github.com/MRsources/MRzero-Core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dims = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0])\n",
    "coil_maps = birdcage_2d(6, image_dimensions=im_dims, relative_radius=0.8)\n",
    "\n",
    "phantom = mr0.util.load_phantom(image_matrix_size)\n",
    "phantom.coil_sens = rearrange(coil_maps[0, ...], 'coils z y x -> coils x y z')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Create the T1 radial Look Locker sequence\n",
    "\n",
    "To create the T1 radial Look Locker sequence, we use the previously imported [t1_radial_look_locker script](../src/mrseq/scripts/t1_radial_look_locker.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence, fname_seq = create_seq(\n",
    "    system=sys_defaults,\n",
    "    fov_xy=float(phantom.size.numpy()[0]),\n",
    "    n_readout=image_matrix_size[0],\n",
    "    n_spokes=600,\n",
    "    rf_flip_angle=rf_flip_angle,\n",
    "    test_report=False,\n",
    "    timing_check=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Simulate the sequence\n",
    "Now, we pass the sequence and the phantom to the MRzero simulation and save the simulated signal as an (ISMR)MRD file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr0_sequence = mr0.Sequence.import_file(str(fname_seq.with_suffix('.seq')))\n",
    "signal, ktraj_adc = mr0.util.simulate(mr0_sequence, phantom, accuracy=1e-1)\n",
    "mr0.sig_to_mrd(fname_mrd, signal, sequence)\n",
    "combine_ismrmrd_files(fname_mrd, Path(f'{fname_seq}_header.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Reconstruct the images at different inversion times\n",
    "\n",
    "We use [MRpro](https://github.com/PTB-MR/MRpro) for the image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata = KData.from_file(str(fname_mrd).replace('.mrd', '_with_traj.mrd'), trajectory=KTrajectoryIsmrmrd())\n",
    "csm = CsmData.from_kdata_inati(kdata[..., 200:, :], downsampled_size=64, smoothing_width=9)\n",
    "\n",
    "n_acq_per_image = 32\n",
    "n_overlap = 16\n",
    "\n",
    "split_indices = torch.arange(kdata.shape[-2]).unfold(dimension=0, size=n_acq_per_image, step=n_overlap)\n",
    "kdata_split = kdata[..., split_indices, :]\n",
    "\n",
    "recon = DirectReconstruction(kdata_split, csm=csm)\n",
    "idata = recon(kdata_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We visualize the coil sensitivity maps which we used for the iterative SENSE reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, csm.shape[1], figsize=(9 * csm.shape[0], 9))\n",
    "for i in range(csm.shape[1]):\n",
    "    ax[i].imshow(csm.data[0, i, 0, :, :].abs(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can now plot the images at different time points along the acquisition, i.e. at different inversion times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "idat = idata.data.abs().numpy().squeeze()\n",
    "fig, ax = plt.subplots(6, idat.shape[0] // 6, figsize=(4 * idata.shape[0] // 6, 6 * 4))\n",
    "ax = ax.flatten()\n",
    "for i in range(idat.shape[0]):\n",
    "    ax[i].imshow(idat[i, :, :], cmap='gray')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Estimate the T1 maps\n",
    "We use a dictionary matching approach to estimate the T1 maps. Afterward, we compare them to the input and ensure they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_time = idata.header.acquisition_time_stamp - kdata.header.acq_info.acquisition_time_stamp[0, 0, 0, 0, 0]\n",
    "dictionary = DictionaryMatchOp(\n",
    "    TransientSteadyStateWithPreparation(\n",
    "        sampling_time=sampling_time.to(torch.float32),\n",
    "        repetition_time=idata.header.tr,\n",
    "        m0_scaling_preparation=-1,\n",
    "        delay_after_preparation=idata.header.ti,\n",
    "    ),\n",
    "    index_of_scaling_parameter=0,\n",
    ")\n",
    "dictionary.append(\n",
    "    torch.tensor(1.0),\n",
    "    torch.linspace(0.1, 5.0, 1000)[None, :, None],\n",
    "    torch.deg2rad(torch.linspace(rf_flip_angle * 0.8, rf_flip_angle * 1.2, 100))[None, None, :],\n",
    ")\n",
    "m0_match, t1_match, fa_match = dictionary(idata.data)\n",
    "\n",
    "t1_input = np.roll(rearrange(phantom.T1.numpy().squeeze()[::-1, ::-1], 'x y -> y x'), shift=(1, 1), axis=(0, 1))\n",
    "fa_input = (\n",
    "    np.abs(np.roll(rearrange(phantom.B1.numpy().squeeze()[::-1, ::-1], 'x y -> y x'), shift=(1, 1), axis=(0, 1))) * 9\n",
    ")\n",
    "obj_mask = np.zeros_like(t1_input)\n",
    "obj_mask[t1_input > 0] = 1\n",
    "fa_input = fa_input * obj_mask\n",
    "t1_measured = t1_match.numpy().squeeze() * obj_mask\n",
    "fa_measured = np.rad2deg(fa_match.numpy().squeeze() * obj_mask)\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
    "for cax in ax.flatten():\n",
    "    cax.set_xticks([])\n",
    "    cax.set_yticks([])\n",
    "\n",
    "im = ax[0, 0].imshow(t1_input, vmin=0, vmax=1.8, cmap=Colormap('lipari').to_mpl())\n",
    "fig.colorbar(im, ax=ax[0, 0], label='Input T1 (s)')\n",
    "\n",
    "im = ax[0, 1].imshow(t1_measured, vmin=0, vmax=1.8, cmap=Colormap('lipari').to_mpl())\n",
    "fig.colorbar(im, ax=ax[0, 1], label='Measured T1 (s)')\n",
    "\n",
    "im = ax[0, 2].imshow(t1_measured - t1_input, vmin=-1.8, vmax=1.8, cmap='bwr')\n",
    "fig.colorbar(im, ax=ax[0, 2], label='Difference T1 (s)')\n",
    "\n",
    "im = ax[1, 0].imshow(fa_input, vmin=0, vmax=12, cmap='magma')\n",
    "fig.colorbar(im, ax=ax[1, 0], label='Input Flip Angle (°)')\n",
    "\n",
    "im = ax[1, 1].imshow(fa_measured, vmin=0, vmax=12, cmap='magma')\n",
    "fig.colorbar(im, ax=ax[1, 1], label='Measured Flip Angle (°)')\n",
    "\n",
    "im = ax[1, 2].imshow(fa_measured - fa_input, vmin=-12, vmax=12, cmap='bwr')\n",
    "fig.colorbar(im, ax=ax[1, 2], label='Difference Flip Angle (°)')\n",
    "\n",
    "relative_error = np.sum(np.abs(t1_input - t1_measured)) / np.sum(np.abs(t1_input))\n",
    "print(f'Relative error of T1 {relative_error}')\n",
    "assert relative_error < 0.08\n",
    "\n",
    "relative_error = np.sum(np.abs(fa_input - fa_measured)) / np.sum(np.abs(fa_input))\n",
    "print(f'Relative error of Flip Angle {relative_error}')\n",
    "assert relative_error < 0.06"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrseq_mrzero",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
