{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# T1 Mapping - MOLLI\n",
    "\n",
    "T1 mapping using a spin echo sequence where a single readout line is acquired after an inversion pulse. \n",
    "Multiple images are obtained at different inversion times. A long repetition time (TR) is used to ensure full signal recovery before the next k-space line is acquired. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MRzeroCore as mr0\n",
    "import numpy as np\n",
    "import torch\n",
    "from cmap import Colormap\n",
    "from einops import rearrange\n",
    "from mrpro.algorithms.reconstruction import IterativeSENSEReconstruction\n",
    "from mrpro.data import CsmData\n",
    "from mrpro.data import KData\n",
    "from mrpro.data import SpatialDimension\n",
    "from mrpro.data.acq_filters import is_coil_calibration_acquisition\n",
    "from mrpro.data.traj_calculators import KTrajectoryCartesian\n",
    "from mrpro.operators import DictionaryMatchOp\n",
    "from mrpro.operators.models import MOLLI\n",
    "from mrpro.phantoms.coils import birdcage_2d\n",
    "\n",
    "from mrseq.scripts.t1_molli_bssfp import main as create_seq\n",
    "from mrseq.utils import sys_defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Settings\n",
    "We are going to use a numerical phantom with a matrix size of 128 x 128. The repetition time is set to 20 seconds to ensure we can accurately estimate long T1 times of the CSF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matrix_size = [64, 64]\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "fname_mrd = Path(tmp.name) / 't1_molli.mrd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Create the digital phantom\n",
    "\n",
    "We use the standard Brainweb phantom from [MRzero](https://github.com/MRsources/MRzero-Core), but we choose the B1-field to be constant everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dims = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0])\n",
    "coil_maps = birdcage_2d(6, image_dimensions=im_dims, relative_radius=0.8)\n",
    "\n",
    "phantom = mr0.util.load_phantom(image_matrix_size)\n",
    "phantom.B1[:] = 1.0\n",
    "phantom.coil_sens = rearrange(coil_maps[0, ...], 'coils z y x -> coils x y z')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Create the MOLLI bSSFP sequence\n",
    "\n",
    "To create the MOLLI bSSFP sequence, we use the previously imported [t1_molli_bssfp script](../src/mrseq/scripts/t1_molli_bssfp.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence, fname_seq = create_seq(\n",
    "    system=sys_defaults,\n",
    "    test_report=False,\n",
    "    timing_check=False,\n",
    "    fov_xy=float(phantom.size.numpy()[0]),\n",
    "    n_readout=image_matrix_size[0],\n",
    "    acceleration=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Simulate the sequence\n",
    "Now, we pass the sequence and the phantom to the MRzero simulation and save the simulated signal as an (ISMR)MRD file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr0_sequence = mr0.Sequence.import_file(str(fname_seq.with_suffix('.seq')))\n",
    "signal, ktraj_adc = mr0.util.simulate(mr0_sequence, phantom, accuracy=1e-2)\n",
    "mr0.sig_to_mrd(fname_mrd, signal, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Reconstruct the images at different inversion times\n",
    "\n",
    "We use [MRpro](https://github.com/PTB-MR/MRpro) for the image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata = KData.from_file(fname_mrd, trajectory=KTrajectoryCartesian())\n",
    "kdata.header.encoding_matrix = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0] * 2)\n",
    "kdata.header.recon_matrix = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0])\n",
    "\n",
    "\n",
    "kdata_calib = KData.from_file(\n",
    "    fname_mrd, trajectory=KTrajectoryCartesian(), acquisition_filter_criterion=is_coil_calibration_acquisition\n",
    ")\n",
    "kdata_calib.header.encoding_matrix = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0] * 2)\n",
    "kdata_calib.header.recon_matrix = SpatialDimension(z=1, y=image_matrix_size[1], x=image_matrix_size[0])\n",
    "csm = CsmData.from_kdata_inati(kdata_calib[0], downsampled_size=64, smoothing_width=9)\n",
    "recon = IterativeSENSEReconstruction(kdata, csm=csm, n_iterations=8)\n",
    "idata = recon(kdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We visualize the coil sensitivity maps which we used for the iterative SENSE reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, csm.shape[1], figsize=(3 * idata.shape[0], 3))\n",
    "for i in range(csm.shape[1]):\n",
    "    ax[i].imshow(csm.data[0, i, 0, :, :].abs(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can now plot the images at different inversion times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "idat = idata.rss().abs().numpy().squeeze()\n",
    "acquisition_time_stamp = idata.header.acquisition_time_stamp.squeeze()\n",
    "ti = np.concatenate(\n",
    "    (\n",
    "        idata.header.ti[0] + acquisition_time_stamp[:5] - acquisition_time_stamp[0],\n",
    "        idata.header.ti[1] + acquisition_time_stamp[5:] - acquisition_time_stamp[5],\n",
    "    )\n",
    ")\n",
    "fig, ax = plt.subplots(1, idat.shape[0], figsize=(3 * idata.shape[0], 3))\n",
    "for i in range(idat.shape[0]):\n",
    "    ax[i].imshow(idat[i, :, :], cmap='gray')\n",
    "    ax[i].set_title(f'TI = {int(np.round(ti[i] * 1000))} ms')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Estimate the T1 maps\n",
    "We use a dictionary matching approach to estimate the T1 maps. Afterward, we compare them to the input and ensure they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = DictionaryMatchOp(MOLLI(ti=torch.as_tensor(ti, dtype=torch.float32)), index_of_scaling_parameter=0)\n",
    "dictionary.append(\n",
    "    torch.tensor(1.0), torch.linspace(0.1, 5.0, 300)[None, :, None], torch.linspace(0.1, 5.0, 300)[None, None, :]\n",
    ")\n",
    "m0_match, c_match, t1_match = dictionary(idata.data)\n",
    "\n",
    "t1_input = np.roll(rearrange(phantom.T1.numpy().squeeze()[::-1, ::-1], 'x y -> y x'), shift=(1, 1), axis=(0, 1))\n",
    "obj_mask = np.zeros_like(t1_input)\n",
    "obj_mask[t1_input > 0] = 1\n",
    "t1_measured = t1_match.numpy().squeeze() * obj_mask\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
    "for cax in ax:\n",
    "    cax.set_xticks([])\n",
    "    cax.set_yticks([])\n",
    "\n",
    "im = ax[0].imshow(t1_input, vmin=0, vmax=1.8, cmap=Colormap('lipari').to_mpl())\n",
    "fig.colorbar(im, ax=ax[0], label='Input T1 (s)')\n",
    "\n",
    "im = ax[1].imshow(t1_measured, vmin=0, vmax=1.8, cmap=Colormap('lipari').to_mpl())\n",
    "fig.colorbar(im, ax=ax[1], label='Measured T1 (s)')\n",
    "\n",
    "im = ax[2].imshow(t1_measured - t1_input, vmin=-1.8, vmax=1.8, cmap='bwr')\n",
    "fig.colorbar(im, ax=ax[2], label='Difference T1 (s)')\n",
    "\n",
    "relative_error = np.sum(np.abs(t1_input - t1_measured)) / np.sum(np.abs(t1_input))\n",
    "print(f'Relative error {relative_error}')\n",
    "assert relative_error < 0.09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrseq_mrzero",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
